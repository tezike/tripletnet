{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.tripletnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaion of a triplet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A triplet network takes in 3 inputs:\n",
    "- The query image\n",
    "- The positive image\n",
    "- The Negative image\n",
    "These 3 images all pass through the same embedding extractor\n",
    "\n",
    "The query image can be a cropped out part of a parent image or an image very similar to the parent image in the embedding space. This parent image will be taken as the postive image because it is very similar to the query image in the embedding space. The negative image however is one that bears no embedding similarity to the positive image.\n",
    "\n",
    "NB: It is important to note however that there are many notions of similarity between items. Items may be similar in color or in brand or gender use etc. This raises the need for us to have conditions of simialrity while building our architecture\n",
    "\n",
    "We will be using a conditional similarity network to learn the different notions of similarities from the triplets while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embeddingnet):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embeddingnet = conditionalnet\n",
    "        \n",
    "    def forward(self, q, p, n, c):\n",
    "        \"\"\"\n",
    "        q: Query Image\n",
    "        p: Positive Image\n",
    "        n: Negative Image\n",
    "        c: Condition of similarity\n",
    "        \"\"\"\n",
    "        \n",
    "        # it is important to normalize the embeddings while using triplets\n",
    "        embedded_x, masknorm_norm_q, embed_norm_q, tot_embed_norm_q = self.conditionalnet(q, c)\n",
    "        embedded_p, masknorm_norm_p, embed_norm_p, tot_embed_norm_p = self.conditionalnet(p, c)\n",
    "        embedded_n, masknorm_norm_n, embed_norm_n, tot_embed_norm_n = self.conditionalnet(n, c)\n",
    "        mask_norm = (masknorm_norm_q + masknorm_norm_p + masknorm_norm_n) / 3\n",
    "        embed_norm = (embed_norm_q + embed_norm_p + embed_norm_n) / 3\n",
    "        mask_embed_norm = (tot_embed_norm_q + tot_embed_norm_p + tot_embed_norm_n) / 3\n",
    "        \n",
    "        pos_dist = F.pairwise_distance(embedded_q, embedded_p, 2)\n",
    "        neg_dist = F.pairwise_distance(embedded_q, embedded_n, 2)\n",
    "        \n",
    "        return pos_dist, neg_dist, mask_norm, embed_norm, mask_embed_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
